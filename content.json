{"meta":{"title":"å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸å¼ºåŒ–å­¦ä¹ ","subtitle":"å­¦ä¹ ç†è®ºã€åœ¨çº¿ä¼˜åŒ–ã€ç½‘ç»œæŠ€æœ¯","description":"","author":"John Doe","url":"https://Reinforcement-Learning.github.io","root":"/"},"pages":[{"title":"","date":"2024-12-12T03:11:49.419Z","comments":true,"path":"research/index.html","permalink":"https://reinforcement-learning.github.io/research/","excerpt":"","text":"ç ”ç©¶æ–¹å‘ Machine Learning Online Learning: Experts, Bandits, Online Convex Optimization, Multi-scale Online Learingï¼ŒOnline Learning with Attacks&#x2F;Corruptions Distributed Learning&#x2F;Estimation Statistical Learning Optimization and Operation Research: Knapsack, Job Scheduling, Ski Rental, Online Linear Programming, Online Decision Making etc. Foundation Model Include both â€œML for Foundation Modelâ€œ and â€œFoundation Model for MLâ€œ, such as optimizing the implementation of LLMs in Edge etc. å‘è¡¨è®ºæ–‡ï¼š Asynchronous Multi-Agent Bandits: Fully Distributed vs. Leader-Coordinated AlgorithmsXuchuang Wang, Janice Chen, Xutong Liu, , Lin Yang*, Mohammad Hajiesmaili, John CS Lui, Don Towsley ACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS), June 2025. (Full Paper) [AISTATS 2023] On-Demand Communication for Asynchronous Multi-Agent Bandits (to appear)Yu-zhen Janice Chen, Lin Yang*, Xuchuang Wang, Xutong Liu, Mohammad Hajiesmaili, John C.S. Lui, Don TowsleyThe 26th International Conference on Artificial Intelligence and Statistics (AISTATS 2023), 2023. [ICLR 2023] Achieve Near-Optimal Individual Regret &amp; Low Communications in Multi-Agent Bandits (to appear)Xuchuang Wang, Lin Yang*, Yu-zhen Janice Chen, Xutong Liu, Mohammad Hajiesmaili, Don Towsley, John C.S. LuiThe Eleventh International Conference on Learning Representations (ICLR 2023), 2023. [SIGMETRICS 2023] The Online Knapsack Problem with DeparturesBo Sun#, Lin Yang#, Mohammad Hajiesmaili, Adam Wierman, Don TowsleyACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS), June 2023. (Full Paper). [SIGMETRICS 2022] Hierarchical Learning Algorithms for Multi-scale Expert ProblemsLin Yang, Yu-zhen Chen, Mohammad Hajiesmaili, Mark Herbster, Don TowsleyACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS), June 2022. (Full Paper)Journal Version: Proceedings of the ACM on Measurement and Analysis of Computing Systems (POMACS), 2022, 6(2): 1-29. [INFOCOM 2022] Distributed Bandits with Heterogeneous AgentsLin Yang, Yu-zhen Chen, Mohammad Hajiesmaili, John CS Lui, Don TowsleyIEEE International Conference on Computer Communications (INFOCOM), 2022. [SIGMETRICS 2022] Competitive Algorithms for Online Multidimensional Knapsack ProblemsLin Yang, Ali Zeynali, Mohammad Hajiesmaili, Ramesh Sitaraman, Donald F. TowsleyACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS), June 2022. (Full Paper)Journal Version: Proceedings of the ACM on Measurement and Analysis of Computing Systems (POMACS), 2021, 5(3): 1-30. [NeurIPS 2021] Cooperative Stochastic Bandits with Asynchronous Agents and Constrained FeedbackLin Yang, Yu-Zhen Janice Chen, Stephen Pasteris, Mohammad Hajiesmaili, John CS Lui, Don TowsleyAdvances in Neural Information Processing Systems (NeurIPS), 2021. [Performance 2021] Competitive Bidding Strategies for Online Linear Optimization with Inventory Management ConstraintsRussell Lee, Yutao Zhou, Lin Yang, Mohammad Hajiesmaili, Ramesh SitaramanIFIP Performance, 2021. Learning Based Control Policy and Regret Analysis for Online Quadratic Optimization with Asymmetric Information Structure Cheng Tan, Lin Yang*, Wing Shing Wong Transactions on Cybernetics, 2021. [NeurIPS 2020] Adversarial Bandits with Corruptions: Regret Lower Bound and No-regret AlgorithmLin Yang, Mohammad Hajiesmaili, Mohammad Sadegh Talebi, John CS Lui, Wing Shing WongAdvances in Neural Information Processing Systems (NeurIPS), 2020. [SIGMETRICS 2020] Online Linear Optimization with Inventory Management ConstraintsLin Yang#, Mohammad Hajiesmaili#, Ramesh Sitaraman, Adam Wierman, Enrique Mallada, Wing Shing WongACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS), June 2020. (Full Paper)Journal Version: Proceedings of the ACM on Measurement and Analysis of Computing Systems (POMACS), 2020, 4(1): 1-29. Online Linear Programming with Uncertain ConstraintsLin Yang, Mohammad H. Hajiesmaili, and Wing Shing WongProceedings of The 53rd Annual Conference on Information Sciences and Systems (CISS). 2019. (Invited Paper) Stabilization of Discrete Time Stochastic System with Input Delay and Control Dependent Noise Cheng Tan, Lin Yang, Fangfang Zhang, Zhenqiang Zhang and Wing Shing WongSystems &amp; Control Letters, 2019, 123: 62â€“68. An Average Queue-Length-Difference-Based Congestion Detection Algorithm in TCP&#x2F;AQM NetworkJin Zhu, Tong Luo, Lin Yang, Wanqing Xie, and G. E. DullerudInternational Journal of Adaptive Control and Signal Processing. 2018. [SIGMETRICS 2017] Hour-Ahead Offering Strategies in Electricity Market for Power Producers with Storage and Intermittent SupplyLin Yang#, Mohammad H. Hajiesmaili#, Hanling Yi, and Minghua ChenACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS), June 2017. (Poster Paper) Gittins Index Based Control Policy for a Class of Pursuit-Evasion ProblemsCheng Tan, Changbao Xu, Lin Yang, and Wing Shing WongIET Control Theory and Applications, 12(1), 110-118, 2017. Competitive Online Algorithms for Geographical Load Balancing in Data Centers with Energy StorageChi-Kin Chau, Lin YangProceedings of the 5th International Workshop on Energy Efficient Data Centres. 2016. An Optimal Vertical Handoff Decision Algorithm for Multiple Services with Different Priorities in Heterogeneous Wireless NetworksJin Zhu, Limin Xu, Lin Yang, Wanqing XieWireless Personal Communications 83 (1), 527-549, 2015. [ComLett] Time Series Analysis for Congestion Detection in TCP&#x2F;AQM NetworksLin Yang, Jin Zhu, Wanqing Xie, and G. E. DullerudIEEE Communications Letters, 19(3), 331-334, 2015. â€‹ (#: Equal Contribution or Co-first Author; *: Corresponding Author)"},{"title":"","date":"2024-12-13T08:23:15.130Z","comments":true,"path":"member/index.html","permalink":"https://reinforcement-learning.github.io/member/","excerpt":"","text":"åŠå…¬å®¤: å—äº¬å¤§å­¦è‹å·æ ¡åŒº ä¸ªäººä¸»é¡µ: https://yanglin2021.github.io/index.html æ•™è‚²èƒŒæ™¯ï¼ˆLin Yangï¼‰ï¼š 2015å¹´8æœˆ - 2018å¹´8æœˆ Ph.D. in Information Engineering, The Chinese University of Hong Kong, Hong Kong. Advisor: Wing Shing Wong (FIEEE) Thesis: Competitive and Regret Analysis for Online Optimization 2012å¹´8æœˆ - 2015å¹´6æœˆ Master in Automatic Control , University of Science and Technology of China, Hefei. Advisor: Jin Zhu 2008å¹´8æœˆ - 2012å¹´6æœˆ Bachelor in Information Science , University of Science and Technology of China, Hefei. é‚®ç®±: linyang@nju.edu.cn, yanglin.cuhk@gmail.com ç›¸å…³é“¾æ¥: homepage , Google Scholar , CV åšå£«ç”Ÿ: ç¡•å£«ç”Ÿ: æœ¬ç§‘ç”Ÿ: ç§‘ç ”åŠ©ç†:"},{"title":"","date":"2024-12-12T03:15:06.939Z","comments":true,"path":"activity/index.html","permalink":"https://reinforcement-learning.github.io/activity/","excerpt":"","text":"å®éªŒå®¤æ´»åŠ¨ å®éªŒå®¤å›¢å»º"},{"title":"","date":"2024-12-13T07:11:06.572Z","comments":true,"path":"project/index.html","permalink":"https://reinforcement-learning.github.io/project/","excerpt":"","text":"é¡¹ç›® XXæ–¹æ³•éªŒè¯å’Œè¯„ä¼° â€” JWKJWé‡å¤§é¡¹ç›® â€” è¯¾é¢˜è´Ÿè´£äºº å¼‚æ„æ•°æ®ç¯å¢ƒä¸­åˆ†å¸ƒå¼åœ¨çº¿å­¦ä¹ ç ”ç©¶ â€” å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘ï¼ˆé’å¹´ï¼‰é¡¹ç›® â€” ä¸»æŒ å¼‚æ„æ•°æ®ç¯å¢ƒåœ°é€šä¿¡åˆ†å¸ƒå¼åœ¨çº¿å­¦ä¹ ç®—æ³•ç ”ç©¶ â€” æ±Ÿè‹çœåŸºç¡€ç ”ç©¶è®¡åˆ’ï¼ˆé’å¹´ï¼‰é¡¹ç›® â€” ä¸»æŒ åŸºäºåœ¨çº¿æœºå™¨å­¦ä¹ çš„TopKæ¨èç®—æ³• â€” æ±Ÿè‹çœåŒåˆ›åšå£«é¡¹ç›® â€” ä¸»æŒ è¾¹ç«¯å¤§æ¨¡å‹çš„è½»é‡åŒ–ä»¥åŠFPGAéƒ¨ç½² â€” è‹å·å¸‚å…³é”®æ ¸å¿ƒæŠ€æœ¯â€œæ­æ¦œæŒ‚å¸…â€æ”»å…³ â€” è¯¾é¢˜è´Ÿè´£äºº åŸºäºå•æå¼æ‹“æ‰‘çš„é«˜æ•ˆé«˜åŠŸç‡å¯†åº¦å¾®å‹å…‰å‚¨é€†å˜å™¨åŠç³»ç»Ÿç ”å‘ â€” è‹å·å¸‚å…³é”®æ ¸å¿ƒæŠ€æœ¯â€œæ­æ¦œæŒ‚å¸…â€æ”»å…³ â€” è¯¾é¢˜è´Ÿè´£äºº åŸºäºè¶‹åŒçš„åˆ†å¸ƒå¼åœ¨çº¿å­¦ä¹ ç ”ç©¶ â€” å…¨å›½é‡ç‚¹å®éªŒå®¤åˆ›æ–°é¡¹ç›®ï¼ˆé’å¹´ï¼‰ â€” ä¸»æŒ åŸºäºäººå·¥æ™ºèƒ½çš„å…‰ä¼ç”µç½‘ç”µå¼§æ£€æµ‹ â€” ä¼ä¸šæ¨ªå‘ â€” ä¸»æŒ é¢å‘æµ‹è¯•åœºæ™¯é›†è´¨é‡è¯„ä¼°çš„è¯„ä¼°å·¥å…·å¼€å‘ â€” 2024èˆªå¤©ä¸€é™¢è”åˆåˆ›æ–° â€” ä¸»æŒ æœºå™¨å­¦ä¹ å‰æ²¿ç†è®ºå’Œç®—æ³•ç ”ç©¶ â€” å—äº¬å¤§å­¦è‹å·æ ¡åŒºäººæ‰å¯åŠ¨ç»è´¹é¡¹ç›® â€” ä¸»æŒ"},{"title":"","date":"2025-02-20T07:09:24.173Z","comments":true,"path":"course/index.html","permalink":"https://reinforcement-learning.github.io/course/","excerpt":"","text":"å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹å†…å®¹æ¦‚è§ˆğŸ“Œ éƒ¨åˆ†ä¸€ï¼šå¼ºåŒ–å­¦ä¹ åŸºç¡€ï¼ˆ4ä¸ªä¸»é¢˜ï¼‰ åŸºç¡€ç†è®ºä¸åŸºæœ¬æ¦‚å¿µ è’™ç‰¹å¡æ´›ä¸æ—¶åºå·®åˆ†å­¦ä¹  å‡½æ•°é€¼è¿‘ ç­–ç•¥æ¢¯åº¦ä¸æ·±åº¦å¼ºåŒ–å­¦ä¹ ã€åœ¨çº¿ä¸ç¦»çº¿å¼ºåŒ–å­¦ä¹  ğŸ¤– éƒ¨åˆ†äºŒï¼šå¤šæ™ºèƒ½ä½“ç³»ç»ŸåŸºç¡€ï¼ˆ3ä¸ªä¸»é¢˜ï¼‰ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç®€ä»‹ åšå¼ˆè®ºä¸çº³ä»€å‡è¡¡ ç»å…¸å¤šæ™ºèƒ½ä½“ç®—æ³• ğŸ”„ éƒ¨åˆ†ä¸‰ï¼šå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆ3~4ä¸ªä¸»é¢˜ï¼‰ ä¸­å¿ƒåŒ–è®­ç»ƒä¸åˆ†æ•£æ‰§è¡Œ åˆä½œå¤šæ™ºèƒ½ä½“ç®—æ³• ç«äº‰ä¸æ··åˆåœºæ™¯ç®—æ³• ğŸš€ éƒ¨åˆ†å››ï¼šé«˜çº§ä¸»é¢˜ä¸åº”ç”¨ï¼ˆ2ä¸ªä¸»é¢˜ï¼‰ å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¼ºåŒ–å­¦ä¹  å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å‰æ²¿ï¼ˆé‚€è¯·æŠ¥å‘Šï¼‰"},{"title":"","date":"2025-03-05T06:08:39.347Z","comments":true,"path":"course_content/index.html","permalink":"https://reinforcement-learning.github.io/course_content/","excerpt":"","text":"ğŸ¤– å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸å¼ºåŒ–å­¦ä¹ ğŸ“Œ è¯¾ç¨‹å†…å®¹æ¦‚è§ˆğŸ† éƒ¨åˆ†ä¸€ï¼šå¼ºåŒ–å­¦ä¹ åŸºç¡€ï¼ˆ4ä¸ªä¸»é¢˜ï¼‰ åŸºç¡€ç†è®ºä¸åŸºæœ¬æ¦‚å¿µ ğŸ“‚ è¯¾ç¨‹PPTä¸‹è½½ è’™ç‰¹å¡æ´›ä¸æ—¶åºå·®åˆ†å­¦ä¹  å‡½æ•°é€¼è¿‘ ç­–ç•¥æ¢¯åº¦ä¸æ·±åº¦å¼ºåŒ–å­¦ä¹  åœ¨çº¿ä¸ç¦»çº¿å¼ºåŒ–å­¦ä¹  ğŸ¤– éƒ¨åˆ†äºŒï¼šå¤šæ™ºèƒ½ä½“ç³»ç»ŸåŸºç¡€ï¼ˆ3ä¸ªä¸»é¢˜ï¼‰ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç®€ä»‹ åšå¼ˆè®ºä¸çº³ä»€å‡è¡¡ ç»å…¸å¤šæ™ºèƒ½ä½“ç®—æ³• ğŸ”„ éƒ¨åˆ†ä¸‰ï¼šå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆ3~4ä¸ªä¸»é¢˜ï¼‰ ä¸­å¿ƒåŒ–è®­ç»ƒä¸åˆ†æ•£æ‰§è¡Œ åˆä½œå¤šæ™ºèƒ½ä½“ç®—æ³• ç«äº‰ä¸æ··åˆåœºæ™¯ç®—æ³• ğŸš€ éƒ¨åˆ†å››ï¼šé«˜çº§ä¸»é¢˜ä¸åº”ç”¨ï¼ˆ2ä¸ªä¸»é¢˜ï¼‰ å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¼ºåŒ–å­¦ä¹  å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å‰æ²¿ï¼ˆé‚€è¯·æŠ¥å‘Šï¼‰"},{"title":"","date":"2025-02-20T07:23:12.342Z","comments":true,"path":"course_resource/index.html","permalink":"https://reinforcement-learning.github.io/course_resource/","excerpt":"","text":"ğŸ“š å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹èµ„æºğŸ“ ä¸Šäº¤å¤§ - å¼ ä¼Ÿæ¥  è¯¾ç¨‹ç½‘é¡µ ğŸ“‚ è¯¾ä»¶ä¸‹è½½ ğŸ“º Bç«™è§†é¢‘ ğŸ« è¥¿æ¹–å¤§å­¦ - WindyLab ğŸ“‚ è¯¾ä»¶ä¸‹è½½ ğŸ“º Bç«™ä¸»é¡µ ğŸ›ï¸ æ–¯å¦ç¦å¤§å­¦ ğŸ“º è¯¾ç¨‹ç½‘ç«™ ğŸ”¬ ç‹æ ‘æ£® (Meta) ğŸ“º YouTube è§†é¢‘"},{"title":"","date":"2025-02-20T07:22:57.012Z","comments":true,"path":"course_work/index.html","permalink":"https://reinforcement-learning.github.io/course_work/","excerpt":"","text":"ğŸ“Š è¯¾ç¨‹è€ƒè¯„æ–¹å¼âœ… è€ƒå‹¤ï¼ˆ10åˆ†ï¼‰ æ¯å­¦æœŸ 2 æ¬¡ç‚¹å ğŸ“– è¯¾ç¨‹ä½œä¸šï¼ˆ20åˆ†ï¼‰ 10 æ¬¡è¯¾åå°å®éªŒç»ƒä¹  ğŸ›  è¯¾ç¨‹å®è·µï¼ˆ20åˆ†ï¼‰ å…± 2 é¢˜ï¼ˆå…¨é€‰ï¼‰ å°ç»„å¤§ä½œä¸šï¼Œæ¯ç»„ 3 äºº ğŸ¯ è¯¾ç¨‹é¡¹ç›®ï¼ˆ50åˆ†ï¼‰ 4 é¢˜ä¸­é€‰ 1 é¢˜ æ¯ç»„ 5 äºº è¯„ä»·æ ‡å‡†ï¼šç³»ç»Ÿã€è®ºæ–‡ã€ä¸“åˆ©ç­‰ ğŸ“¤ æäº¤æ–¹å¼ æäº¤ç½‘å€ï¼šé‡‡ç”¨è¯¾ç¨‹è‡ªä¸»ä»£ç è®­ç»ƒå¹³å° [DODO] åŠŸèƒ½ï¼šå®ç°ä»£ç æäº¤ã€éªŒè¯"}],"posts":[{"title":"","slug":"å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹","date":"2025-02-17T05:45:55.294Z","comments":true,"path":"2025/02/17/å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹/","link":"","permalink":"https://reinforcement-learning.github.io/2025/02/17/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/","excerpt":"","text":"å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹å†…å®¹æ¦‚è§ˆğŸ“Œ éƒ¨åˆ†ä¸€ï¼šå¼ºåŒ–å­¦ä¹ åŸºç¡€ï¼ˆ4ä¸ªä¸»é¢˜ï¼‰ åŸºç¡€ç†è®ºä¸åŸºæœ¬æ¦‚å¿µ è’™ç‰¹å¡æ´›ä¸æ—¶åºå·®åˆ†å­¦ä¹  å‡½æ•°é€¼è¿‘ ç­–ç•¥æ¢¯åº¦ä¸æ·±åº¦å¼ºåŒ–å­¦ä¹ ã€åœ¨çº¿ä¸ç¦»çº¿å¼ºåŒ–å­¦ä¹  ğŸ¤– éƒ¨åˆ†äºŒï¼šå¤šæ™ºèƒ½ä½“ç³»ç»ŸåŸºç¡€ï¼ˆ3ä¸ªä¸»é¢˜ï¼‰ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç®€ä»‹ åšå¼ˆè®ºä¸çº³ä»€å‡è¡¡ ç»å…¸å¤šæ™ºèƒ½ä½“ç®—æ³• ğŸ”„ éƒ¨åˆ†ä¸‰ï¼šå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆ3~4ä¸ªä¸»é¢˜ï¼‰ ä¸­å¿ƒåŒ–è®­ç»ƒä¸åˆ†æ•£æ‰§è¡Œ åˆä½œå¤šæ™ºèƒ½ä½“ç®—æ³• ç«äº‰ä¸æ··åˆåœºæ™¯ç®—æ³• ğŸš€ éƒ¨åˆ†å››ï¼šé«˜çº§ä¸»é¢˜ä¸åº”ç”¨ï¼ˆ2ä¸ªä¸»é¢˜ï¼‰ å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¼ºåŒ–å­¦ä¹  å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å‰æ²¿ï¼ˆé‚€è¯·æŠ¥å‘Šï¼‰","categories":[],"tags":[]}],"categories":[],"tags":[]}